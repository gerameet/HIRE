# Default Experiment Configuration

experiment:
  name: "baseline_experiment"
  quick_mode: false  # Quick test mode (fewer images, faster models)
  save_intermediates: true  # Save embeddings, parse graphs, etc.
  seed: 42  # Random seed for reproducibility

data:
  images_path: "../images"
  max_images: null  # null = all images, or specify number for quick tests
  
segmentation:
  model: "dummy"  # Options: dummy, sam, yolo, mask2former, segformer, clipseg, detectron2
  checkpoint: null  # Path to model checkpoint (required for some models)
  model_type: null  # Model variant (e.g., vit_b for SAM)
  min_confidence: 0.5
  min_area: 100
  text_prompts: null  # For CLIPSeg (list of prompts)

embedding:
  method: "dinov2"  # Options: dummy, clip, dinov2, mae
  cache_dir: "cache/embeddings"
  use_cache: true

hierarchy:
  method: "bottom_up"  # Options: bottom_up, top_down, hybrid, gnn
  spatial_threshold: 0.3
  containment_threshold: 0.7
  max_depth: 5

evaluation:
  enabled: false  # Run evaluation after processing
  tasks: ["retrieval"]  # Options: retrieval, classification
  top_k: 5
  class_labels: ["person", "vehicle", "animal", "object", "building", "furniture", "food"]

output:
  save_parse_graphs: true
  save_embeddings: true
  save_visualizations: true

gpu:
  device: null  # null for auto-detect, or "cuda", "cuda:0", "cpu"
  allow_cpu_fallback: true
  batch_size: 8
